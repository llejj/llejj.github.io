<!DOCTYPE html>
<html>

<head>
    <title>Alex Sun's Portfolio</title>
    <link href='./stylesheet.css' rel='stylesheet'>
</head>

<body>
    <h1>Alex Sun' Portfolio</h1>
    <p>Hi, I'm an undergraduate at UC Berkeley studying Applied Math and Computer Science graduating in Spring 2025. Below are projects from my resume that could use elaborating. I hope that, under the guidance of an internship, I can work on larger projects and gain experience solving real-world problems. </p>

    <!--
<h2>ChatGPT API for Translation</h2>
This is a simple Python script that uses ChatGPT to translate text. It takes the original text file and outputs a translated version. I've used it on some previously untranslated novels<br><br>

[insert sample]
-->
    <div>
        <h2><a href="https://github.com/llejj/HMM_stocks">HMM Stocks</a></h2>
        <p>I used a Hidden Markov Model to analyze historical $SPY data. My model had two hidden states, and its emissions were the daily % price changes.</p>

        <p>The transition matrix:</p>
        <center>
            <table border="1">
                <thead>
                    <tr>
                        <th></th>
                        <th>State 0</th>
                        <th>State 1</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <th>State 0</th>
                        <th>0.975</th>
                        <th>0.025</th>
                    </tr>
                    <tr>
                        <th>State 1</th>
                        <th>0.017</th>
                        <th>0.983</th>
                    </tr>
                </tbody>
            </table>
        </center>

        <p>Probability distribution for each state:</p>
        <center>
            <img src="images/State0.png" alt="State 0's Probability Distribution" class="inline" />
            <img src="images/State1.png" alt="State 1's Probability Distribution" class="inline" />
        </center>

        <p>Most likely sequence of states decoded with the Viterbi Algorithm:</p>
        <center>
            <img src="images/SPY.png" alt="$SPY price and HMM states" class="inline" />
        </center>

        <p>It seems that State 0 reflects more stable bull markets, while State 1 reflects increased volatility during bear
        markets. This model offers a simple description of the stock market. So yeah, HMM's are kinda cool.</p>

    </div>

    <div>
        <h2><a href="https://github.com/llejj/Speech_Recognition">HMM Speech Recognition</a></h2>
        <p>I implemented a Hierarchical Hidden Markov Model (HHMM) based on "The Hierarchical Hidden Markov Model: Analysis and Applications" by Shai Fine, Yoram Singer, and Naftali Tishby. In particular, I implemented the Baum-Welch and Viterbi algorithms.</p>

        <p>Then, I began to train an HHMM for speech recognition. The basic idea for the algorithm was: 
            <ol>
                <li>Extract MFCC features from audio signal (which should even out differences in voice)</li>
                <li>The deepest layer of the HHMM decodes phonemes from MFCC features</li>
                <li>The next layer of the HHMM decodes words from phonemes</li>
                <li>The top layer decodes common word patterns from words</li>
            </ol>
        </p>

        <p>I managed to train the deepest layer separately as a simple HMM, but I had issues running the Generalized Baum-Welch on the full model. In the future, I plan to rewrite my HHMM more efficiently so that the training process runs smoothly. I worked on this project before I took important classes such as D.S. and Algorithms, so I feel I could do a much better job now.</p>
    </div>

</body>

</html>